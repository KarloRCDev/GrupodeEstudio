{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bosques aleatorios\n",
    "\n",
    "Utilizando un algoritmo de aprendizaje automático más sofisticado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "Los árboles de decisión te dejan con una decisión difícil. Un árbol profundo con muchas hojas se ajustará demasiado porque cada predicción proviene de datos históricos de sólo las pocas casas en su hoja. Pero un árbol poco profundo y con pocas hojas tendrá un mal desempeño porque no logra capturar tantas distinciones en los datos sin procesar.\n",
    "\n",
    "Incluso las técnicas de modelado más sofisticadas de hoy enfrentan esta tensión entre el desajuste y el sobreajuste. Sin embargo, muchos modelos tienen ideas inteligentes que pueden conducir a un mejor rendimiento. Veremos el bosque aleatorio como ejemplo.\n",
    "\n",
    "El bosque aleatorio utiliza muchos árboles y realiza una predicción promediando las predicciones de cada árbol componente. Generalmente tiene una precisión predictiva mucho mejor que un árbol de decisión único y funciona bien con parámetros predeterminados. Si continúa modelando, podrá aprender más modelos con un rendimiento aún mejor, pero muchos de ellos son sensibles a la hora de obtener los parámetros correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Ya has visto el código para cargar los datos varias veces. Al final de la carga de datos, tenemos las siguientes variables:\n",
    "\n",
    ". train_X\n",
    "\n",
    ". valor_X\n",
    "\n",
    ". train_y\n",
    "\n",
    ". val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un modelo de bosque aleatorio de manera similar a cómo construimos un árbol de decisión en scikit-learn, esta vez usando la clase RandomForestRegressor en lugar de DecisionTreeRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191669.7536453626\n",
      "0.724358168671448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))\n",
    "print(r2_score(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Es probable que haya margen de mejora adicional, pero se trata de una gran mejora con respecto al error del mejor árbol de decisión de 250.000. Hay parámetros que le permiten cambiar el rendimiento del bosque aleatorio de la misma manera que cambiamos la profundidad máxima del árbol de decisión único. Pero una de las mejores características de los modelos Random Forest es que generalmente funcionan razonablemente incluso sin este ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
