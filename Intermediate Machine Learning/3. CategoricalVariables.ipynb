{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables categóricas\n",
    "\n",
    "Hay muchos datos no numéricos por ahí. Aquí se explica cómo usarlo para el aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial, aprenderá qué es una variable categórica, junto con tres enfoques para manejar este tipo de datos.\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Una variable categórica toma sólo un número limitado de valores.\n",
    "\n",
    "Considere una encuesta que le pregunte con qué frecuencia desayuna y ofrezca cuatro opciones: \"Nunca\", \"Rara vez\", \"La mayoría de los días\" o \"Todos los días\". En este caso, los datos son categóricos, porque las respuestas caen en un conjunto fijo de categorías.\n",
    "Si las personas respondieran a una encuesta sobre qué marca de automóvil poseen, las respuestas se clasificarían en categorías como \"Honda\", \"Toyota\" y \"Ford\". En este caso, los datos también son categóricos.\n",
    "Recibirá un error si intenta conectar estas variables en la mayoría de los modelos de aprendizaje automático en Python sin preprocesarlas primero. En este tutorial, compararemos tres enfoques que puede utilizar para preparar sus datos categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tres enfoques\n",
    "#### 1) Eliminar variables categóricas\n",
    "El enfoque más sencillo para tratar con variables categóricas es simplemente eliminarlas del conjunto de datos. Este enfoque sólo funcionará bien si las columnas no contienen información útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Codificación ordinal\n",
    "La codificación ordinal asigna cada valor único a un número entero diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enfoque supone un orden de las categorías: \"Nunca\" (0) < \"Rara vez\" (1) < \"La mayoría de los días\" (2) < \"Todos los días\" (3).\n",
    "\n",
    "Esta suposición tiene sentido en este ejemplo, porque existe una clasificación indiscutible de las categorías. No todas las variables categóricas tienen un orden claro en los valores, pero nos referimos a aquellas que lo tienen como variables ordinales. Para los modelos basados en árboles (como árboles de decisión y bosques aleatorios), se puede esperar que la codificación ordinal funcione bien con variables ordinales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Codificación One-Hot\n",
    "La codificación one-hot crea nuevas columnas que indican la presencia (o ausencia) de cada valor posible en los datos originales. Para entender esto, trabajaremos con un ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el conjunto de datos original, \"Color\" es una variable categórica con tres categorías: \"Rojo\", \"Amarillo\" y \"Verde\". La codificación one-hot correspondiente contiene una columna para cada valor posible y una fila para cada fila del conjunto de datos original. Siempre que el valor original fuera \"Rojo\", ponemos un 1 en la columna \"Rojo\"; si el valor original era \"Amarillo\", ponemos un 1 en la columna \"Amarillo\", y así sucesivamente.\n",
    "\n",
    "A diferencia de la codificación ordinal, la codificación one-hot no supone un ordenamiento de las categorías. Por lo tanto, puede esperar que este enfoque funcione particularmente bien si no hay un orden claro en los datos categóricos (por ejemplo, \"Rojo\" no es ni más ni menos que \"Amarillo\"). Nos referimos a las variables categóricas sin una clasificación intrínseca como variables nominales.\n",
    "\n",
    "La codificación one-hot generalmente no funciona bien si la variable categórica toma una gran cantidad de valores (es decir, generalmente no la usará para variables que toman más de 15 valores diferentes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "Como en el tutorial anterior, trabajaremos con el conjunto de datos de Melbourne Housing.\n",
    "\n",
    "No nos centraremos en el paso de carga de datos. En cambio, puedes imaginar que estás en un punto en el que ya tienes los datos de entrenamiento y validación en X_train, X_valid, y_train e y_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echamos un vistazo a los datos de entrenamiento con el método head() a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, obtenemos una lista de todas las variables categóricas en los datos de entrenamiento.\n",
    "\n",
    "Hacemos esto verificando el tipo de datos (o tipo d) de cada columna. El tipo de objeto indica que una columna tiene texto (en teoría, hay otras cosas que podrían ser, pero eso no es importante para nuestros propósitos). Para este conjunto de datos, las columnas con texto indican variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir función para medir la calidad de cada enfoque\n",
    "\n",
    "Definimos una función score_dataset() para comparar los tres enfoques diferentes para tratar con variables categóricas. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio. En general, queremos que el MAE sea lo más bajo posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del método 1 (eliminar variables categóricas)\n",
    "Soltamos las columnas de objetos con el método select_dtypes()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Landsize  Lattitude  \\\n",
       "12167      1       5.0    3182.0       1.0       1.0       0.0  -37.85984   \n",
       "6524       2       8.0    3016.0       2.0       2.0     193.0  -37.85800   \n",
       "8413       3      12.6    3020.0       3.0       1.0     555.0  -37.79880   \n",
       "2919       3      13.0    3046.0       3.0       1.0     265.0  -37.70830   \n",
       "6043       3      13.3    3020.0       3.0       1.0     673.0  -37.76230   \n",
       "...      ...       ...       ...       ...       ...       ...        ...   \n",
       "13123      3       5.2    3056.0       3.0       1.0     212.0  -37.77695   \n",
       "3264       3      10.5    3081.0       3.0       1.0     748.0  -37.74160   \n",
       "9845       4       6.7    3058.0       4.0       2.0     441.0  -37.73572   \n",
       "10799      3      12.0    3073.0       3.0       1.0     606.0  -37.72057   \n",
       "2732       4       6.4    3011.0       4.0       2.0     319.0  -37.79430   \n",
       "\n",
       "       Longtitude  Propertycount  \n",
       "12167   144.98670        13240.0  \n",
       "6524    144.90050         6380.0  \n",
       "8413    144.82200         3755.0  \n",
       "2919    144.91580         8870.0  \n",
       "6043    144.82720         4217.0  \n",
       "...           ...            ...  \n",
       "13123   144.95785        11918.0  \n",
       "3264    145.04810         2947.0  \n",
       "9845    144.97256        11204.0  \n",
       "10799   145.02615        21650.0  \n",
       "2732    144.88750         7570.0  \n",
       "\n",
       "[10864 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puntuación del método 2 (codificación ordinal)\n",
    "Scikit-learn tiene una clase OrdinalEncoder que se puede utilizar para obtener codificaciones ordinales. Recorremos las variables categóricas y aplicamos el codificador ordinal por separado a cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda de código anterior, para cada columna, asignamos aleatoriamente cada valor único a un número entero diferente. Este es un enfoque común que es más sencillo que proporcionar etiquetas personalizadas; sin embargo, podemos esperar un aumento adicional en el rendimiento si proporcionamos etiquetas mejor informadas para todas las variables ordinales.\n",
    "\n",
    "#### Puntuación del método 3 (codificación One-Hot)\n",
    "Usamos la clase OneHotEncoder de scikit-learn para obtener codificaciones one-hot. Hay una serie de parámetros que se pueden utilizar para personalizar su comportamiento.\n",
    "\n",
    ". Configuramos handle_unknown='ignore' para evitar errores cuando los datos de validación contienen clases que no están representadas en los datos de entrenamiento, y\n",
    "\n",
    ". establecer sparse=False garantiza que las columnas codificadas se devuelvan como una matriz numerosa (en lugar de una matriz dispersa).\n",
    "\n",
    "Para usar el codificador, proporcionamos solo las columnas categóricas que queremos que se codifiquen en caliente. Por ejemplo, para codificar los datos de entrenamiento, proporcionamos X_train[object_cols]. (object_cols en la celda de código siguiente es una lista de los nombres de columnas con datos categóricos, por lo que X_train[object_cols] contiene todos los datos categóricos en el conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "166089.4893009678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Aplicar codificador one-hot a cada columna con datos categóricos\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Eliminar columnas categóricas (se reemplazarán con codificación one-hot)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Agregue columnas codificadas en one-hot  a funciones numéricas\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Asegúrese de que todas las columnas tengan tipo de cadena\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Landsize  Lattitude  \\\n",
       "12167      1       5.0    3182.0       1.0       1.0       0.0  -37.85984   \n",
       "6524       2       8.0    3016.0       2.0       2.0     193.0  -37.85800   \n",
       "8413       3      12.6    3020.0       3.0       1.0     555.0  -37.79880   \n",
       "2919       3      13.0    3046.0       3.0       1.0     265.0  -37.70830   \n",
       "6043       3      13.3    3020.0       3.0       1.0     673.0  -37.76230   \n",
       "...      ...       ...       ...       ...       ...       ...        ...   \n",
       "13123      3       5.2    3056.0       3.0       1.0     212.0  -37.77695   \n",
       "3264       3      10.5    3081.0       3.0       1.0     748.0  -37.74160   \n",
       "9845       4       6.7    3058.0       4.0       2.0     441.0  -37.73572   \n",
       "10799      3      12.0    3073.0       3.0       1.0     606.0  -37.72057   \n",
       "2732       4       6.4    3011.0       4.0       2.0     319.0  -37.79430   \n",
       "\n",
       "       Longtitude  Propertycount    0  ...    6    7    8    9   10   11   12  \\\n",
       "12167   144.98670        13240.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "6524    144.90050         6380.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8413    144.82200         3755.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2919    144.91580         8870.0  0.0  ...  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "6043    144.82720         4217.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...           ...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "13123   144.95785        11918.0  1.0  ...  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "3264    145.04810         2947.0  1.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "9845    144.97256        11204.0  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "10799   145.02615        21650.0  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "2732    144.88750         7570.0  1.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        13   14   15  \n",
       "12167  1.0  0.0  0.0  \n",
       "6524   0.0  1.0  0.0  \n",
       "8413   0.0  1.0  0.0  \n",
       "2919   0.0  0.0  0.0  \n",
       "6043   0.0  1.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "13123  0.0  0.0  0.0  \n",
       "3264   0.0  0.0  0.0  \n",
       "9845   0.0  0.0  0.0  \n",
       "10799  0.0  0.0  0.0  \n",
       "2732   0.0  1.0  0.0  \n",
       "\n",
       "[10864 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OH_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué enfoque es mejor?\n",
    "\n",
    "En este caso, eliminar las columnas categóricas (Método 1) obtuvo el peor resultado, ya que obtuvo la puntuación MAE más alta. En cuanto a los otros dos enfoques, dado que los puntajes MAE devueltos tienen un valor tan cercano, no parece haber ningún beneficio significativo para uno sobre el otro.\n",
    "\n",
    "En general, la codificación one-hot (método 3) suele tener el mejor rendimiento, y eliminar las columnas categóricas (método 1) suele tener el peor rendimiento, pero varía según el caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "El mundo está lleno de datos categóricos. ¡Serás un científico de datos mucho más eficaz si sabes cómo utilizar este tipo de datos común!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, trabajará con datos del concurso de precios de vivienda para usuarios de Kaggle Learn.\n",
    "\n",
    "Ejecute la siguiente celda de código sin cambios para cargar los conjuntos de entrenamiento y validación en X_train, X_valid, y_train e y_valid. El conjunto de prueba se carga en X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "​\n",
    "# Read the data\n",
    "X = pd.read_csv('../input/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "​\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "​\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "​\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la siguiente celda de código para imprimir las primeras cinco filas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que el conjunto de datos contiene variables numéricas y categóricas. Deberá codificar los datos categóricos antes de entrenar un modelo.\n",
    "\n",
    "Para comparar diferentes modelos, usará la misma función score_dataset() del tutorial. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: eliminar columnas con datos categóricos\n",
    "Comenzará con el enfoque más sencillo. Utilice la celda de código siguiente para preprocesar los datos en X_train y X_valid para eliminar columnas con datos categóricos. Establezca los DataFrames preprocesados en drop_X_train y drop_X_valid, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código para obtener el MAE para este enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    MAE from Approach 1 (Drop categorical variables):\n",
    "    17837.82570776256\n",
    "\n",
    "Antes de pasar a la codificación ordinal, investigaremos el conjunto de datos. Específicamente, veremos la columna 'Condición2'. La siguiente celda de código imprime las entradas únicas tanto en el conjunto de entrenamiento como en el de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: codificación ordinal\n",
    "#### Parte A\n",
    "Si ahora escribe código en:\n",
    "\n",
    ". ajustar un codificador ordinal a los datos de entrenamiento, y luego\n",
    "\n",
    ". Úselo para transformar los datos de entrenamiento y validación,\n",
    "\n",
    "obtendrás un error. ¿Puedes ver por qué este es el caso? (Necesitará utilizar el resultado anterior para responder esta pregunta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar un codificador ordinal a una columna de los datos de entrenamiento crea una etiqueta de valor entero correspondiente para cada valor único que aparece en los datos de entrenamiento. En el caso de que los datos de validación contengan valores que no aparecen también en los datos de entrenamiento, el codificador arrojará un error, porque estos valores no tendrán un número entero asignado. Observe que la columna 'Condición2' en los datos de validación contiene los valores 'RRAn' y 'RRNn', pero estos no aparecen en los datos de entrenamiento; por lo tanto, si intentamos usar un codificador ordinal con scikit-learn, el El código arrojará un error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema común que encontrará con los datos del mundo real y existen muchos enfoques para solucionarlo. Por ejemplo, puede escribir un codificador ordinal personalizado para manejar nuevas categorías. Sin embargo, el enfoque más sencillo es eliminar las columnas categóricas problemáticas.\n",
    "\n",
    "Ejecute la celda de código siguiente para guardar las columnas problemáticas en una lista de Python bad_label_cols. Del mismo modo, las columnas que pueden codificarse de forma ordinal de forma segura se almacenan en good_label_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte B\n",
    "Utilice la siguiente celda de código para codificar ordinalmente los datos en X_train y X_valid. Establezca los DataFrames preprocesados en label_X_train y label_X_valid, respectivamente.\n",
    "\n",
    "Proporcionamos el código a continuación para eliminar las columnas categóricas en bad_label_cols del conjunto de datos.\n",
    "Debe codificar de forma ordinal las columnas categóricas en good_label_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código para obtener el MAE para este enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, ha probado dos enfoques diferentes para tratar con variables categóricas. Y ha visto que codificar datos categóricos produce mejores resultados que eliminar columnas del conjunto de datos.\n",
    "\n",
    "Pronto probará la codificación one-hot. Antes de eso, hay un tema adicional que debemos cubrir. Comience ejecutando la siguiente celda de código sin cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Investigar la cardinalidad\n",
    "#### Parte A\n",
    "El resultado anterior muestra, para cada columna con datos categóricos, el número de valores únicos en la columna. Por ejemplo, la columna \"Street\" en los datos de entrenamiento tiene dos valores únicos: \"Grvl\" y \"Pave\", correspondientes a un camino de grava y un camino pavimentado, respectivamente.\n",
    "\n",
    "Nos referimos al número de entradas únicas de una variable categórica como la cardinalidad de esa variable categórica. Por ejemplo, la variable 'Street' tiene cardinalidad 2.\n",
    "\n",
    "Utilice el resultado anterior para responder las preguntas siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many categorical variables in the training data\n",
    "# have cardinality greater than 10?\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# Fill in the line below: How many columns are needed to one-hot encode the \n",
    "# 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte B\n",
    "Para conjuntos de datos grandes con muchas filas, la codificación one-hot puede ampliar considerablemente el tamaño del conjunto de datos. Por esta razón, normalmente solo codificaremos columnas con una cardinalidad relativamente baja. Luego, las columnas de alta cardinalidad se pueden eliminar del conjunto de datos o podemos usar codificación ordinal.\n",
    "\n",
    "Como ejemplo, considere un conjunto de datos con 10.000 filas y que contiene una columna categórica con 100 entradas únicas.\n",
    "\n",
    "Si esta columna se reemplaza con la codificación one-hot correspondiente, ¿cuántas entradas se agregan al conjunto de datos?\n",
    "Si reemplazamos la columna con la codificación ordinal, ¿cuántas entradas se agregan?\n",
    "Utilice sus respuestas para completar las líneas a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many entries are added to the dataset by \n",
    "# replacing the column with a one-hot encoding?\n",
    "OH_entries_added = 1e4*100 - 1e4\n",
    "\n",
    "# Fill in the line below: How many entries are added to the dataset by\n",
    "# replacing the column with an ordinal encoding?\n",
    "label_entries_added = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, experimentará con la codificación one-hot. Pero, en lugar de codificar todas las variables categóricas en el conjunto de datos, solo creará una codificación única para columnas con cardinalidad menor que 10.\n",
    "\n",
    "Ejecute la siguiente celda de código sin cambios para configurar low_cardinality_cols en una lista de Python que contenga las columnas que se codificarán en caliente. Asimismo, high_cardinality_cols contiene una lista de columnas categóricas que se eliminarán del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: codificación one-hot\n",
    "Utilice la siguiente celda de código para codificar en caliente los datos en X_train y X_valid. Establezca los DataFrames preprocesados en OH_X_train y OH_X_valid, respectivamente.\n",
    "\n",
    "La lista completa de columnas categóricas en el conjunto de datos se puede encontrar en la lista de Python object_cols.\n",
    "Solo debe codificar una vez las columnas categóricas en low_cardinality_cols. Todas las demás columnas categóricas deben eliminarse del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
