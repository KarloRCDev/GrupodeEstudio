{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores faltantes\n",
    "\n",
    "Los valores faltantes suceden. Esté preparado para este desafío común en conjuntos de datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial, aprenderá tres enfoques para lidiar con valores faltantes. Luego comparará la efectividad de estos enfoques en un conjunto de datos del mundo real.\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Hay muchas formas en que los datos pueden terminar con valores faltantes. Por ejemplo,\n",
    "\n",
    "=> Una casa de 2 dormitorios no incluirá el valor del tamaño de un tercer dormitorio.\n",
    "\n",
    "=> Un encuestado puede optar por no compartir sus ingresos.\n",
    "\n",
    "La mayoría de las bibliotecas de aprendizaje automático (incluida scikit-learn) dan un error si intentas construir un modelo usando datos con valores faltantes. Por lo tanto, deberá elegir una de las estrategias siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres enfoques\n",
    "\n",
    "1) Una opción simple: eliminar columnas con valores faltantes\n",
    "\n",
    "La opción más sencilla es eliminar las columnas con valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menos que falten la mayoría de los valores en las columnas eliminadas, el modelo pierde acceso a mucha información (¡potencialmente útil!) con este enfoque. Como ejemplo extremo, considere un conjunto de datos con 10.000 filas, donde a una columna importante le falta una sola entrada. ¡Este enfoque eliminaría la columna por completo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Una mejor opción: la imputación\n",
    "\n",
    "La imputación completa los valores faltantes con algún número. Por ejemplo, podemos completar el valor medio en cada columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor imputado no será exactamente correcto en la mayoría de los casos, pero generalmente conduce a modelos más precisos que los que se obtendrían si eliminara la columna por completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Una extensión de la imputación\n",
    "\n",
    "La imputación es el enfoque estándar y normalmente funciona bien. Sin embargo, los valores imputados pueden estar sistemáticamente por encima o por debajo de sus valores reales (que no se recopilaron en el conjunto de datos). O las filas con valores faltantes pueden ser únicas de alguna otra manera. En ese caso, su modelo haría mejores predicciones al considerar qué valores faltaban originalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este enfoque, imputamos los valores faltantes, como antes. Y, además, para cada columna a la que le faltan entradas en el conjunto de datos original, agregamos una nueva columna que muestra la ubicación de las entradas imputadas.\n",
    "\n",
    "En algunos casos, esto mejorará significativamente los resultados. En otros casos, no ayuda en absoluto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "En el ejemplo, trabajaremos con el conjunto de datos de Melbourne Housing. Nuestro modelo utilizará información como la cantidad de habitaciones y el tamaño del terreno para predecir el precio de la vivienda.\n",
    "\n",
    "No nos centraremos en el paso de carga de datos. En cambio, puedes imaginar que estás en un punto en el que ya tienes los datos de entrenamiento y validación en X_train, X_valid, y_train e y_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Select target\n",
    "y = data.Price\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "melb_predictors = data.drop(['Price'], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "12167      1       5.0    3182.0       1.0       1.0  1.0       0.0   \n",
       "6524       2       8.0    3016.0       2.0       2.0  1.0     193.0   \n",
       "8413       3      12.6    3020.0       3.0       1.0  1.0     555.0   \n",
       "2919       3      13.0    3046.0       3.0       1.0  1.0     265.0   \n",
       "6043       3      13.3    3020.0       3.0       1.0  2.0     673.0   \n",
       "...      ...       ...       ...       ...       ...  ...       ...   \n",
       "13123      3       5.2    3056.0       3.0       1.0  2.0     212.0   \n",
       "3264       3      10.5    3081.0       3.0       1.0  1.0     748.0   \n",
       "9845       4       6.7    3058.0       4.0       2.0  2.0     441.0   \n",
       "10799      3      12.0    3073.0       3.0       1.0  1.0     606.0   \n",
       "2732       4       6.4    3011.0       4.0       2.0  1.0     319.0   \n",
       "\n",
       "       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n",
       "12167           NaN     1940.0  -37.85984   144.98670        13240.0  \n",
       "6524            NaN        NaN  -37.85800   144.90050         6380.0  \n",
       "8413            NaN        NaN  -37.79880   144.82200         3755.0  \n",
       "2919            NaN     1995.0  -37.70830   144.91580         8870.0  \n",
       "6043          673.0     1970.0  -37.76230   144.82720         4217.0  \n",
       "...             ...        ...        ...         ...            ...  \n",
       "13123           NaN        NaN  -37.77695   144.95785        11918.0  \n",
       "3264          101.0     1950.0  -37.74160   145.04810         2947.0  \n",
       "9845          255.0     2002.0  -37.73572   144.97256        11204.0  \n",
       "10799           NaN        NaN  -37.72057   145.02615        21650.0  \n",
       "2732          130.0     1915.0  -37.79430   144.88750         7570.0  \n",
       "\n",
       "[10864 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir función para medir la calidad de cada enfoque\n",
    "\n",
    "Definimos una función score_dataset() para comparar diferentes enfoques para tratar con valores faltantes. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntuación del método 1 (eliminar columnas con valores faltantes)\n",
    "\n",
    "Dado que estamos trabajando con conjuntos de entrenamiento y validación, tenemos cuidado de eliminar las mismas columnas en ambos DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Landsize  Lattitude  \\\n",
       "12167      1       5.0    3182.0       1.0       1.0       0.0  -37.85984   \n",
       "6524       2       8.0    3016.0       2.0       2.0     193.0  -37.85800   \n",
       "8413       3      12.6    3020.0       3.0       1.0     555.0  -37.79880   \n",
       "2919       3      13.0    3046.0       3.0       1.0     265.0  -37.70830   \n",
       "6043       3      13.3    3020.0       3.0       1.0     673.0  -37.76230   \n",
       "...      ...       ...       ...       ...       ...       ...        ...   \n",
       "13123      3       5.2    3056.0       3.0       1.0     212.0  -37.77695   \n",
       "3264       3      10.5    3081.0       3.0       1.0     748.0  -37.74160   \n",
       "9845       4       6.7    3058.0       4.0       2.0     441.0  -37.73572   \n",
       "10799      3      12.0    3073.0       3.0       1.0     606.0  -37.72057   \n",
       "2732       4       6.4    3011.0       4.0       2.0     319.0  -37.79430   \n",
       "\n",
       "       Longtitude  Propertycount  \n",
       "12167   144.98670        13240.0  \n",
       "6524    144.90050         6380.0  \n",
       "8413    144.82200         3755.0  \n",
       "2919    144.91580         8870.0  \n",
       "6043    144.82720         4217.0  \n",
       "...           ...            ...  \n",
       "13123   144.95785        11918.0  \n",
       "3264    145.04810         2947.0  \n",
       "9845    144.97256        11204.0  \n",
       "10799   145.02615        21650.0  \n",
       "2732    144.88750         7570.0  \n",
       "\n",
       "[10864 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntuación del Método 2 (Imputación)\n",
    "\n",
    "A continuación, usamos SimpleImputer para reemplazar los valores faltantes con el valor medio en cada columna.\n",
    "\n",
    "Aunque es simple, completar el valor medio generalmente funciona bastante bien (pero esto varía según el conjunto de datos). Si bien los estadísticos han experimentado con formas más complejas de determinar los valores imputados (como la imputación de regresión, por ejemplo), las estrategias complejas generalmente no brindan ningún beneficio adicional una vez que se conectan los resultados a modelos sofisticados de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation):\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# La imputación eliminó los nombres de las columnas; devuelvelos\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "0        1.0       5.0    3182.0       1.0       1.0  1.0       0.0   \n",
       "1        2.0       8.0    3016.0       2.0       2.0  1.0     193.0   \n",
       "2        3.0      12.6    3020.0       3.0       1.0  1.0     555.0   \n",
       "3        3.0      13.0    3046.0       3.0       1.0  1.0     265.0   \n",
       "4        3.0      13.3    3020.0       3.0       1.0  2.0     673.0   \n",
       "...      ...       ...       ...       ...       ...  ...       ...   \n",
       "10859    3.0       5.2    3056.0       3.0       1.0  2.0     212.0   \n",
       "10860    3.0      10.5    3081.0       3.0       1.0  1.0     748.0   \n",
       "10861    4.0       6.7    3058.0       4.0       2.0  2.0     441.0   \n",
       "10862    3.0      12.0    3073.0       3.0       1.0  1.0     606.0   \n",
       "10863    4.0       6.4    3011.0       4.0       2.0  1.0     319.0   \n",
       "\n",
       "       BuildingArea    YearBuilt  Lattitude  Longtitude  Propertycount  \n",
       "0        153.764119  1940.000000  -37.85984   144.98670        13240.0  \n",
       "1        153.764119  1964.839866  -37.85800   144.90050         6380.0  \n",
       "2        153.764119  1964.839866  -37.79880   144.82200         3755.0  \n",
       "3        153.764119  1995.000000  -37.70830   144.91580         8870.0  \n",
       "4        673.000000  1970.000000  -37.76230   144.82720         4217.0  \n",
       "...             ...          ...        ...         ...            ...  \n",
       "10859    153.764119  1964.839866  -37.77695   144.95785        11918.0  \n",
       "10860    101.000000  1950.000000  -37.74160   145.04810         2947.0  \n",
       "10861    255.000000  2002.000000  -37.73572   144.97256        11204.0  \n",
       "10862    153.764119  1964.839866  -37.72057   145.02615        21650.0  \n",
       "10863    130.000000  1915.000000  -37.79430   144.88750         7570.0  \n",
       "\n",
       "[10864 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el Método 2 tiene un MAE más bajo que el Método 1, por lo que el Método 2 funcionó mejor en este conjunto de datos.\n",
    "\n",
    "### Puntuación del método 3 (una extensión de la imputación)\n",
    "\n",
    "A continuación, imputamos los valores faltantes y al mismo tiempo realizamos un seguimiento de qué valores se imputaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "178927.503183954\n"
     ]
    }
   ],
   "source": [
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>Car_was_missing</th>\n",
       "      <th>BuildingArea_was_missing</th>\n",
       "      <th>YearBuilt_was_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.98670</td>\n",
       "      <td>13240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.90050</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.82200</td>\n",
       "      <td>3755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.91580</td>\n",
       "      <td>8870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.82720</td>\n",
       "      <td>4217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.77695</td>\n",
       "      <td>144.95785</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>-37.74160</td>\n",
       "      <td>145.04810</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>-37.73572</td>\n",
       "      <td>144.97256</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>153.764119</td>\n",
       "      <td>1964.839866</td>\n",
       "      <td>-37.72057</td>\n",
       "      <td>145.02615</td>\n",
       "      <td>21650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>-37.79430</td>\n",
       "      <td>144.88750</td>\n",
       "      <td>7570.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10864 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "0        1.0       5.0    3182.0       1.0       1.0  1.0       0.0   \n",
       "1        2.0       8.0    3016.0       2.0       2.0  1.0     193.0   \n",
       "2        3.0      12.6    3020.0       3.0       1.0  1.0     555.0   \n",
       "3        3.0      13.0    3046.0       3.0       1.0  1.0     265.0   \n",
       "4        3.0      13.3    3020.0       3.0       1.0  2.0     673.0   \n",
       "...      ...       ...       ...       ...       ...  ...       ...   \n",
       "10859    3.0       5.2    3056.0       3.0       1.0  2.0     212.0   \n",
       "10860    3.0      10.5    3081.0       3.0       1.0  1.0     748.0   \n",
       "10861    4.0       6.7    3058.0       4.0       2.0  2.0     441.0   \n",
       "10862    3.0      12.0    3073.0       3.0       1.0  1.0     606.0   \n",
       "10863    4.0       6.4    3011.0       4.0       2.0  1.0     319.0   \n",
       "\n",
       "       BuildingArea    YearBuilt  Lattitude  Longtitude  Propertycount  \\\n",
       "0        153.764119  1940.000000  -37.85984   144.98670        13240.0   \n",
       "1        153.764119  1964.839866  -37.85800   144.90050         6380.0   \n",
       "2        153.764119  1964.839866  -37.79880   144.82200         3755.0   \n",
       "3        153.764119  1995.000000  -37.70830   144.91580         8870.0   \n",
       "4        673.000000  1970.000000  -37.76230   144.82720         4217.0   \n",
       "...             ...          ...        ...         ...            ...   \n",
       "10859    153.764119  1964.839866  -37.77695   144.95785        11918.0   \n",
       "10860    101.000000  1950.000000  -37.74160   145.04810         2947.0   \n",
       "10861    255.000000  2002.000000  -37.73572   144.97256        11204.0   \n",
       "10862    153.764119  1964.839866  -37.72057   145.02615        21650.0   \n",
       "10863    130.000000  1915.000000  -37.79430   144.88750         7570.0   \n",
       "\n",
       "       Car_was_missing  BuildingArea_was_missing  YearBuilt_was_missing  \n",
       "0                  0.0                       1.0                    0.0  \n",
       "1                  0.0                       1.0                    1.0  \n",
       "2                  0.0                       1.0                    1.0  \n",
       "3                  0.0                       1.0                    0.0  \n",
       "4                  0.0                       0.0                    0.0  \n",
       "...                ...                       ...                    ...  \n",
       "10859              0.0                       1.0                    1.0  \n",
       "10860              0.0                       0.0                    0.0  \n",
       "10861              0.0                       0.0                    0.0  \n",
       "10862              0.0                       1.0                    1.0  \n",
       "10863              0.0                       0.0                    0.0  \n",
       "\n",
       "[10864 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_X_train_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, el Método 3 tuvo un desempeño ligeramente peor que el Método 2.\n",
    "\n",
    "### Entonces, ¿por qué la imputación funcionó mejor que eliminar las columnas?\n",
    "\n",
    "Los datos de entrenamiento tienen 10864 filas y 12 columnas, donde tres columnas contienen datos faltantes. Para cada columna, faltan menos de la mitad de las entradas. Por lo tanto, eliminar las columnas elimina mucha información útil, por lo que tiene sentido que la imputación funcione mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10864, 12)\n",
      "Car               49\n",
      "BuildingArea    5156\n",
      "YearBuilt       4307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Como es común, imputar valores faltantes (en los Métodos 2 y 3) arrojó mejores resultados, en comparación con cuando simplemente eliminamos las columnas con valores faltantes (en el Método 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, trabajará con datos del concurso de precios de vivienda para usuarios de Kaggle Learn.\n",
    "\n",
    "Ejecute la siguiente celda de código sin cambios para cargar los conjuntos de entrenamiento y validación en X_train, X_valid, y_train e y_valid. El conjunto de prueba se carga en X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Read the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_full \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../input/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m X_test_full \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Remove rows with missing target, separate target from predictors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\karlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la siguiente celda de código para imprimir las primeras cinco filas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya puedes ver algunos valores faltantes en las primeras filas. En el siguiente paso, obtendrá una comprensión más completa de los valores faltantes en el conjunto de datos.\n",
    "\n",
    "### Paso 1: investigación preliminar\n",
    "\n",
    "Ejecute la celda de código a continuación sin cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (1168, 36)\n",
    "    LotFrontage    212\n",
    "    MasVnrArea       6\n",
    "    GarageYrBlt     58\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte A\n",
    "\n",
    "Utilice el resultado anterior para responder las siguientes preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many rows are in the training data?\n",
    "num_rows = 1168\n",
    "\n",
    "# Fill in the line below: How many columns in the training data\n",
    "# have missing values?\n",
    "num_cols_with_missing = 3 \n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in \n",
    "# all of the training data?\n",
    "tot_missing = 276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B\n",
    "\n",
    "Teniendo en cuenta sus respuestas anteriores, ¿cuál cree que es probablemente el mejor enfoque para abordar los valores faltantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que faltan relativamente pocas entradas en los datos (a la columna con el mayor porcentaje de valores faltantes le faltan menos del 20% de sus entradas), podemos esperar que eliminar columnas probablemente no produzca buenos resultados. Esto se debe a que estaríamos desperdiciando muchos datos valiosos y, por lo tanto, la imputación probablemente funcionará mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar diferentes enfoques para tratar los valores faltantes, usará la misma función score_dataset() del tutorial. Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: elimine las columnas con valores faltantes\n",
    "\n",
    "En este paso, procesará previamente los datos en X_train y X_valid para eliminar columnas con valores faltantes. Establezca los DataFrames preprocesados en reduce_X_train y reduce_X_valid, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()] \n",
    "# Your code here\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código sin cambios para obtener el MAE para este enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    MAE (Drop columns with missing values):\n",
    "    17837.82570776256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Imputación\n",
    "#### Parte A\n",
    "\n",
    "Utilice la siguiente celda de código para imputar los valores faltantes con el valor medio a lo largo de cada columna. Establezca los DataFrames preprocesados en imputed_X_train e imputed_X_valid. Asegúrese de que los nombres de las columnas coincidan con los de X_train y X_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer() \n",
    "# Your code here\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código sin cambios para obtener el MAE para este enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    MAE (Imputation):\n",
    "    18062.894611872147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B\n",
    "\n",
    "Compare el MAE de cada enfoque. ¿Te sorprende algo de los resultados? ¿Por qué cree que un enfoque funcionó mejor que el otro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que hay tan pocos valores faltantes en el conjunto de datos, esperaríamos que la imputación funcionara mejor que eliminar columnas por completo. Sin embargo, vemos que eliminar columnas funciona ligeramente mejor. Si bien esto probablemente pueda atribuirse en parte al ruido en el conjunto de datos, otra posible explicación es que el método de imputación no coincide muy bien con este conjunto de datos. Es decir, tal vez en lugar de completar el valor medio, tenga más sentido establecer cada valor faltante en un valor de 0, completar el valor encontrado con más frecuencia o utilizar algún otro método. Por ejemplo, considere la columna GarageYrBlt (que indica el año en que se construyó el garaje). Es probable que, en algunos casos, un valor faltante indique una casa que no tiene garaje. ¿Tiene más sentido completar el valor mediano en cada columna en este caso? ¿O podríamos obtener mejores resultados completando el valor mínimo en cada columna? No está del todo claro qué es lo mejor en este caso, pero tal vez podamos descartar algunas opciones de inmediato; por ejemplo, establecer los valores faltantes en esta columna en 0 probablemente produzca resultados horribles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: generar predicciones de prueba\n",
    "\n",
    "En este paso final, utilizará cualquier enfoque que elija para abordar los valores faltantes. Una vez que haya preprocesado las funciones de entrenamiento y validación, entrenará y evaluará un modelo de bosque aleatorio. Luego, procesará previamente los datos de la prueba antes de generar predicciones que puedan enviarse a la competencia.\n",
    "\n",
    "#### Parte A\n",
    "\n",
    "Utilice la siguiente celda de código para preprocesar los datos de entrenamiento y validación. Establezca los DataFrames preprocesados en final_X_train y final_X_valid. ¡Puedes utilizar cualquier enfoque que elijas aquí! Para que este paso se marque como correcto solo debes asegurarte de:\n",
    "\n",
    ". los DataFrames preprocesados tienen el mismo número de columnas,\n",
    "\n",
    ". los DataFrames preprocesados no tienen valores faltantes,\n",
    "\n",
    ". final_X_train e y_train tienen el mismo número de filas, y\n",
    "\n",
    ". final_X_valid e y_valid tienen el mismo número de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "final_imputer = SimpleImputer(strategy='median')\n",
    "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
    "\n",
    "# Preprocessed training and validation features\n",
    "final_X_train.columns = X_train.columns\n",
    "final_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código para entrenar y evaluar un modelo de bosque aleatorio. (Tenga en cuenta que no usamos la función score_dataset() anterior, ¡porque pronto usaremos el modelo entrenado para generar predicciones de prueba!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    MAE (Your approach):\n",
    "    17791.59899543379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B\n",
    "\n",
    "Utilice la siguiente celda de código para preprocesar los datos de su prueba. Asegúrese de utilizar un método que coincida con la forma en que procesó previamente los datos de entrenamiento y validación, y configure las funciones de prueba preprocesadas en final_X_test.\n",
    "\n",
    "Luego, utilice las funciones de prueba preprocesadas y el modelo entrenado para generar predicciones de prueba en preds_test.\n",
    "\n",
    "Para que este paso se marque como correcto, solo necesita asegurarse de:\n",
    "\n",
    ". el DataFrame de prueba preprocesado no tiene valores faltantes, y\n",
    "\n",
    ". final_X_test tiene el mismo número de filas que X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: preprocess test data\n",
    "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda de código sin cambios para guardar sus resultados en un archivo CSV que pueda enviarse directamente a la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envía tus resultados\n",
    "\n",
    "Una vez que haya completado con éxito el Paso 4, estará listo para enviar sus resultados a la tabla de clasificación. (También aprendió cómo hacer esto en el ejercicio anterior. Si necesita un recordatorio de cómo hacerlo, siga las instrucciones a continuación).\n",
    "\n",
    "Primero, deberás unirte a la competencia si aún no lo has hecho. Así que abre una nueva ventana haciendo clic en este enlace. Luego haga clic en el botón Unirse a la competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, siga las instrucciones a continuación:\n",
    "\n",
    "1. Comience haciendo clic en el botón Guardar versión en la esquina superior derecha de la ventana. Esto generará una ventana emergente.\n",
    "\n",
    "2. Asegúrese de que la opción Guardar y ejecutar todo esté seleccionada y luego haga clic en el botón Guardar.\n",
    "\n",
    "3. Esto genera una ventana en la esquina inferior izquierda del cuaderno. Una vez que haya terminado de ejecutarse, haga clic en el número a la derecha del botón Guardar versión. Esto muestra una lista de versiones a la derecha de la pantalla. Haga clic en los puntos suspensivos (...) a la derecha de la versión más reciente y seleccione Abrir en el Visor. Esto lo lleva al modo de visualización de la misma página. Deberá desplazarse hacia abajo para volver a estas instrucciones.\n",
    "\n",
    "4. Haga clic en la pestaña Datos cerca de la parte superior de la pantalla. Luego, haga clic en el archivo que desea enviar y haga clic en el botón Enviar para enviar sus resultados a la tabla de clasificación.\n",
    "\n",
    "¡Ya te has presentado exitosamente al concurso!\n",
    "\n",
    "Si desea seguir trabajando para mejorar su rendimiento, seleccione el botón Editar en la parte superior derecha de la pantalla. Luego puedes cambiar tu código y repetir el proceso. Hay mucho margen de mejora y ascenderás en la clasificación a medida que trabajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
